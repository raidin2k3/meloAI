{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n",
      "Requirement already satisfied: praw in c:\\users\\lab\\anaconda3\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\lab\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.153.0)\n",
      "Requirement already satisfied: flask in c:\\users\\lab\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\lab\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lab\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: transformers==4.46.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: torch==2.3.1+cu121 in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision==0.18.1+cu121 in c:\\users\\lab\\anaconda3\\lib\\site-packages (0.18.1+cu121)\n",
      "Requirement already satisfied: accelerate in c:\\users\\lab\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (2021.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torchvision==0.18.1+cu121) (10.3.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.36.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.23.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\lab\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lab\\anaconda3\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.1+cu121) (2.1.3)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\lab\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1+cu121) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\lab\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1+cu121) (2021.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from requests->transformers==4.46.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from requests->transformers==4.46.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from requests->transformers==4.46.2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from requests->transformers==4.46.2) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.1+cu121) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\lab\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\lab\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\lab\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orchvision (c:\\Users\\Lab\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orchvision (c:\\Users\\Lab\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orchvision (c:\\Users\\Lab\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#installing libs\n",
    "%pip install praw pandas vaderSentiment google-api-python-client flask datasets scikit-learn tensorflow tf-keras transformers==4.46.2 torch==2.3.1+cu121 torchvision==0.18.1+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libs\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "from werkzeug.serving import run_simple\n",
    "import threading\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "from flask import Flask, render_template_string, request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping Reddit for Dataset to Train on Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit creds\n",
    "reddit = praw.Reddit(\n",
    "    user_agent=\"Comment Extraction (by /u/lestergreeks)\",\n",
    "    client_id=\"YiK4KHJXxneFv0IiV8aOhg\", \n",
    "    client_secret=\"8GfGLUx8E62B3sBUwJcie43RDBQm7A\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting all comments from top10 posts of a subreddit\n",
    "subreddit = reddit.subreddit('technews')\n",
    "\n",
    "all_comments = pd.DataFrame()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(submission):\n",
    "    posts = []\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    count = 0\n",
    "    for top_level_comment in submission.comments.list():\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        if (top_level_comment.author and \"bot\" not in top_level_comment.author.name.lower() \n",
    "            and not top_level_comment.stickied):\n",
    "            posts.append(top_level_comment.body.encode('utf-8', 'ignore').decode('utf-8'))\n",
    "    \n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_posts():\n",
    "    global all_comments\n",
    "    attempt = 0\n",
    "    for submission in subreddit.rising(limit=15):\n",
    "        try:\n",
    "            print(f\"Processing post: {submission.title}\")\n",
    "            posts = extract_comments(submission)\n",
    "            posts_df = pd.DataFrame(posts, columns=[\"body\"])\n",
    "            indexNames = posts_df[(posts_df.body == '[removed]') | (posts_df.body == '[deleted]')].index\n",
    "            posts_df.drop(indexNames, inplace=True)\n",
    "            posts_df['post_title'] = submission.title\n",
    "            posts_df['post_time'] = datetime.fromtimestamp(submission.created_utc, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            all_comments = pd.concat([all_comments, posts_df], ignore_index=True)\n",
    "        \n",
    "        except praw.exceptions.RedditAPIException as e:\n",
    "            if \"RATELIMIT\" in str(e):\n",
    "                attempt += 1\n",
    "                sleep_time = 120 * attempt\n",
    "                print(f\"Rate limit hit. Sleeping for {sleep_time} seconds. Error: {e}\")\n",
    "                time.sleep(sleep_time) \n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Encountered an error: {e}\")\n",
    "                continue\n",
    "    \n",
    "        time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing post: Two undersea internet cables connecting Finland and Sweden to Europe have been cut — EU leaders suspect sabotage\n",
      "Processing post: Student-made rocket smashes 20-year-old world record, soaring 470,400 feet above Earth | Aftershock II also set a new amateur rocket speed record of 3,602 mph\n",
      "Processing post: AI photos showing girl students with nude bodies roil private school in Pennsylvania\n",
      "Processing post: AI cloning of celebrity voices outpacing the law, experts warn\n",
      "Processing post: Forget driverless cars. One company wants autonomous helicopters to spray crops and fight fires\n",
      "Processing post: US lawyers will reportedly try to force Google to sell Chrome and unbundle Android\n",
      "Processing post: Apple Further Expanding Into Ads, Now Directly Selling Ads in News App\n",
      "Processing post: Indian news agency ANI sues OpenAI for unsanctioned content use in AI training\n",
      "Processing post: Microsoft’s new Windows Resiliency Initiative aims to avoid another CrowdStrike incident\n",
      "Processing post: Spotify abused to promote pirated software and game cheats\n",
      "Processing post: AMD-powered El Capitan is now the world's fastest supercomputer with 1.7 exaflops of performance — fastest Intel machine falls to third place on Top500 list | AMDomination.\n",
      "Processing post: I cloned my voice with AI and even my wife can’t tell the difference\n",
      "Processing post: Ukraine rolls out dozens of AI systems to help its drones hit targets\n",
      "Processing post: OpenAI accused of trying to profit off AI model inspection in court | How do you get an AI model to confess what's inside?\n",
      "Processing post: AI Tools Are Changing How We Plan Trips with Smart Travel Solutions\n"
     ]
    }
   ],
   "source": [
    "process_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seems like an act of war to me if there was sa...</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Suspect' sabotage? Ummm. Should read, *EU lea...</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Didn’t Russia just threaten this?</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Listen all y’all this is sabotage.</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It'll be ten by next week\\n\\nFucking grow a sp...</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Money isn’t a true part of the system. It’s a ...</td>\n",
       "      <td>Ukraine rolls out dozens of AI systems to help...</td>\n",
       "      <td>2024-11-18 12:04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Maybe attach some electrodes to its GPUs and a...</td>\n",
       "      <td>OpenAI accused of trying to profit off AI mode...</td>\n",
       "      <td>2024-11-19 01:35:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Report; What are your Prime Directives?\\n\\nTha...</td>\n",
       "      <td>OpenAI accused of trying to profit off AI mode...</td>\n",
       "      <td>2024-11-19 01:35:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Attach electrodes to the Sam Altman model and ...</td>\n",
       "      <td>OpenAI accused of trying to profit off AI mode...</td>\n",
       "      <td>2024-11-19 01:35:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Who knows, it might like that</td>\n",
       "      <td>OpenAI accused of trying to profit off AI mode...</td>\n",
       "      <td>2024-11-19 01:35:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    Seems like an act of war to me if there was sa...   \n",
       "1    'Suspect' sabotage? Ummm. Should read, *EU lea...   \n",
       "2                    Didn’t Russia just threaten this?   \n",
       "3                   Listen all y’all this is sabotage.   \n",
       "4    It'll be ten by next week\\n\\nFucking grow a sp...   \n",
       "..                                                 ...   \n",
       "473  Money isn’t a true part of the system. It’s a ...   \n",
       "474  Maybe attach some electrodes to its GPUs and a...   \n",
       "475  Report; What are your Prime Directives?\\n\\nTha...   \n",
       "476  Attach electrodes to the Sam Altman model and ...   \n",
       "477                      Who knows, it might like that   \n",
       "\n",
       "                                            post_title            post_time  \n",
       "0    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "1    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "2    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "3    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "4    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "..                                                 ...                  ...  \n",
       "473  Ukraine rolls out dozens of AI systems to help...  2024-11-18 12:04:35  \n",
       "474  OpenAI accused of trying to profit off AI mode...  2024-11-19 01:35:12  \n",
       "475  OpenAI accused of trying to profit off AI mode...  2024-11-19 01:35:12  \n",
       "476  OpenAI accused of trying to profit off AI mode...  2024-11-19 01:35:12  \n",
       "477  OpenAI accused of trying to profit off AI mode...  2024-11-19 01:35:12  \n",
       "\n",
       "[478 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments.to_csv('red_data_2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labelling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'red_data_2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows to understand the structure\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seems like an act of war to me if there was sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Suspect' sabotage? Ummm. Should read, *EU lea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Didn’t Russia just threaten this?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Listen all y’all this is sabotage.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It'll be ten by next week\\n\\nFucking grow a sp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  score\n",
       "0  Seems like an act of war to me if there was sa...      0\n",
       "1  'Suspect' sabotage? Ummm. Should read, *EU lea...      0\n",
       "2                  Didn’t Russia just threaten this?      0\n",
       "3                 Listen all y’all this is sabotage.      0\n",
       "4  It'll be ten by next week\\n\\nFucking grow a sp...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to classify sentiment using VADER\n",
    "def classify_sentiment_vader(text):\n",
    "    sentiment_score = analyzer.polarity_scores(str(text))\n",
    "    # Classify as negative, neutral, or positive based on compound score\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 2  # Positive\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 0  # Negative\n",
    "    else:\n",
    "        return 1  # Neutral\n",
    "\n",
    "# Apply the VADER sentiment classification to the 'body' column\n",
    "data['score'] = data['body'].apply(classify_sentiment_vader)\n",
    "\n",
    "# Check the results\n",
    "data[['body', 'score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('red_data_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Sentimental Analysis on YT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key here\n",
    "API_KEY = \"AIzaSyCKz6fxf2IvH8z8LIp5mpm76LB9u9fxHUU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube Comments Extraction using YT.v3 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get comments for a given video ID\n",
    "def get_comments(video_id, max_comments=100, order=\"relevance\"):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "    \n",
    "    comments = []\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        maxResults=max_comments,\n",
    "        textFormat=\"plainText\",\n",
    "        order=order\n",
    "    )\n",
    "    \n",
    "    while request and len(comments) < max_comments:\n",
    "        try:\n",
    "            response = request.execute()\n",
    "        \n",
    "            # Loop through each comment in the response\n",
    "            for item in response.get(\"items\", []):\n",
    "                full_comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append(full_comment)  # Store the full comment\n",
    "                \n",
    "                # Stop if we have reached the max comments\n",
    "                if len(comments) >= max_comments:\n",
    "                    break\n",
    "        \n",
    "            # Check for more comments (pagination)\n",
    "            request = youtube.commentThreads().list_next(request, response)\n",
    "        except HttpError as e:\n",
    "            if \"commentsDisabled\" in str(e):\n",
    "                print(f\"Comments are disabled for Video ID: {video_id}. Skipping this video.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"An unexpected error occurred with Video ID: {video_id}. Error: {e}\")\n",
    "                break\n",
    "\n",
    "    return comments[:max_comments]  # Return up to max_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_videos(query, max_videos=10):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "    \n",
    "    # Search for videos based on the query\n",
    "    request = youtube.search().list(\n",
    "        q=query,\n",
    "        part=\"snippet\",\n",
    "        order=\"viewCount\",\n",
    "        maxResults=max_videos,\n",
    "        type=\"video\"\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    video_data = []  # List to hold video data and comments\n",
    "\n",
    "    for item in response.get(\"items\", []):\n",
    "        video_id = item[\"id\"][\"videoId\"]\n",
    "        video_title = item[\"snippet\"][\"title\"]  # Get video title\n",
    "        print(f\"Fetching comments for Video ID: {video_id}\") \n",
    "        \n",
    "        # Get comments and handle errors (skipping videos with disabled comments)\n",
    "        comments = get_comments(video_id)\n",
    "        \n",
    "        if comments:  # If comments were successfully fetched\n",
    "            for comment in comments:\n",
    "                video_data.append({\"video_id\": video_id, \"video_title\": video_title, \"comment\": comment})\n",
    "    \n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER INPUT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for Video ID: 2cukB4_hDCI\n",
      "Fetching comments for Video ID: DxREm3s1scA\n",
      "Fetching comments for Video ID: cpraXaw7dyc\n",
      "Fetching comments for Video ID: 2lLZ9AWhcNo\n",
      "Fetching comments for Video ID: XiQkeWOFwmk\n",
      "Fetching comments for Video ID: fgm5uZaS3-E\n",
      "Fetching comments for Video ID: DB1027Bfpmo\n",
      "Fetching comments for Video ID: Mu-eK72ioDk\n",
      "Fetching comments for Video ID: nAgTgwak7ME\n",
      "Fetching comments for Video ID: 8vsTNFUFJEU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Robots with guns does not give me a warm and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>\"Yee haw\" killed me💀💀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Dude : \"Now give me back my gun\"\\nRobot : \"giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Guy: Nice job! I’ll take my gun back.\\nRobot: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>*10 seconds later*\\nRobot:\"Now we have to chex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                 video_title  \\\n",
       "0  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "1  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "2  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "3  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "4  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "\n",
       "                                             comment  \n",
       "0  Robots with guns does not give me a warm and f...  \n",
       "1                              \"Yee haw\" killed me💀💀  \n",
       "2  Dude : \"Now give me back my gun\"\\nRobot : \"giv...  \n",
       "3  Guy: Nice job! I’ll take my gun back.\\nRobot: ...  \n",
       "4  *10 seconds later*\\nRobot:\"Now we have to chex...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"tesla we robot\"  # Your search query\n",
    "top_videos_comments = get_top_videos(query, max_videos=10)  # Fetch top 10 videos\n",
    "\n",
    "# Convert the results into a DataFrame for better readability\n",
    "df = pd.DataFrame(top_videos_comments)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Robots with guns does not give me a warm and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>\"Yee haw\" killed me💀💀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Dude : \"Now give me back my gun\"\\nRobot : \"giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Guy: Nice job! I’ll take my gun back.\\nRobot: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>*10 seconds later*\\nRobot:\"Now we have to chex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>“Hey Jerry, you got that jack rabbit chip?”\\nJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>When you see a Terminator and it asks for your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>That shirt gone be wrinkled as hell 😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>Such smooth movements. No arthritis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>This is gonna be the start of the robots right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                 video_title  \\\n",
       "0    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "1    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "2    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "3    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "4    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "..           ...                                         ...   \n",
       "995  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "996  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "997  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "998  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "999  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "\n",
       "                                               comment  \n",
       "0    Robots with guns does not give me a warm and f...  \n",
       "1                                \"Yee haw\" killed me💀💀  \n",
       "2    Dude : \"Now give me back my gun\"\\nRobot : \"giv...  \n",
       "3    Guy: Nice job! I’ll take my gun back.\\nRobot: ...  \n",
       "4    *10 seconds later*\\nRobot:\"Now we have to chex...  \n",
       "..                                                 ...  \n",
       "995  “Hey Jerry, you got that jack rabbit chip?”\\nJ...  \n",
       "996  When you see a Terminator and it asks for your...  \n",
       "997              That shirt gone be wrinkled as hell 😂  \n",
       "998                Such smooth movements. No arthritis  \n",
       "999  This is gonna be the start of the robots right...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('red_data_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results_yt(query):\n",
    "    top_videos_comments = get_top_videos(query, max_videos=10)  # Fetch top 10 videos\n",
    "\n",
    "    # Convert the results into a DataFrame for better readability\n",
    "    df = pd.DataFrame(top_videos_comments)\n",
    "    df.to_csv('red_data_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Model begins here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model v3.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('red_data_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to Dataset format compatible with Hugging Face Trainer\n",
    "def preprocess_data(df):\n",
    "    return {'text': df['body'], 'label': df['score']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(df))\n",
    "train_data = df[:train_size]\n",
    "test_data = df[train_size:]\n",
    "\n",
    "# Apply preprocessing and convert the data into the proper format\n",
    "preprocessed_train = df[:train_size].apply(preprocess_data, axis=1).to_list()\n",
    "preprocessed_test = df[train_size:].apply(preprocess_data, axis=1).to_list()\n",
    "# Convert preprocessed data into Dataset objects\n",
    "train_dataset = Dataset.from_list(preprocessed_train)\n",
    "test_dataset = Dataset.from_list(preprocessed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3f3ccb87534d19831a050175e53f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a29d4e3cf874c9abe3a2baef3983272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/96 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "# Set format to PyTorch tensors for Trainer\n",
    "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lab\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',               # output directory\n",
    "    evaluation_strategy=\"epoch\",          # evaluation strategy (evaluate at the end of each epoch)\n",
    "    learning_rate=2e-5,                   # learning rate\n",
    "    per_device_train_batch_size=16,       # batch size for training\n",
    "    per_device_eval_batch_size=16,        # batch size for evaluation\n",
    "    num_train_epochs=3,                   # number of training epochs\n",
    "    weight_decay=0.01,                    # strength of weight decay\n",
    "    logging_dir='./logs',                 # directory for storing logs\n",
    "    logging_steps=10,                     # log every 10 steps\n",
    "    save_strategy=\"epoch\"                 # save model at the end of every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred: EvalPrediction):\n",
    "    predictions, labels = pred.predictions, pred.label_ids\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_score': f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc6a5b3148a4729810ab23a59c56b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lab\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0952, 'grad_norm': 52.557411193847656, 'learning_rate': 1.7222222222222224e-05, 'epoch': 0.42}\n",
      "{'loss': 1.0322, 'grad_norm': 16.69443702697754, 'learning_rate': 1.4444444444444446e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5e5adf03e54f82bcaaf33f4aa68dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9675526022911072, 'eval_accuracy': 0.5833333333333334, 'eval_f1_score': 0.5097713864306784, 'eval_runtime': 0.8294, 'eval_samples_per_second': 115.744, 'eval_steps_per_second': 7.234, 'epoch': 1.0}\n",
      "{'loss': 1.0508, 'grad_norm': 3.5998733043670654, 'learning_rate': 1.1666666666666668e-05, 'epoch': 1.25}\n",
      "{'loss': 1.044, 'grad_norm': 5.822893142700195, 'learning_rate': 8.888888888888888e-06, 'epoch': 1.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2426609b3f2e4aa99a84a871f190a7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0240317583084106, 'eval_accuracy': 0.375, 'eval_f1_score': 0.29566922724952927, 'eval_runtime': 0.8382, 'eval_samples_per_second': 114.533, 'eval_steps_per_second': 7.158, 'epoch': 2.0}\n",
      "{'loss': 0.9925, 'grad_norm': 5.4666008949279785, 'learning_rate': 6.111111111111112e-06, 'epoch': 2.08}\n",
      "{'loss': 0.9954, 'grad_norm': 114.84964752197266, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.5}\n",
      "{'loss': 0.9749, 'grad_norm': 15.098381996154785, 'learning_rate': 5.555555555555555e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab063f196e946fc97c000929642805f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0272399187088013, 'eval_accuracy': 0.3541666666666667, 'eval_f1_score': 0.26270969721767595, 'eval_runtime': 0.8044, 'eval_samples_per_second': 119.336, 'eval_steps_per_second': 7.459, 'epoch': 3.0}\n",
      "{'train_runtime': 39.4688, 'train_samples_per_second': 29.036, 'train_steps_per_second': 1.824, 'train_loss': 1.0242701487408743, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=72, training_loss=1.0242701487408743, metrics={'train_runtime': 39.4688, 'train_samples_per_second': 29.036, 'train_steps_per_second': 1.824, 'total_flos': 301527976716288.0, 'train_loss': 1.0242701487408743, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bert_tokenizer\\\\tokenizer_config.json',\n",
       " './fine_tuned_bert_tokenizer\\\\special_tokens_map.json',\n",
       " './fine_tuned_bert_tokenizer\\\\vocab.txt',\n",
       " './fine_tuned_bert_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine_tuned_bert_model')\n",
    "tokenizer.save_pretrained('./fine_tuned_bert_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('./fine_tuned_bert_model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./fine_tuned_bert_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to predict sentiment with percentage outputs\n",
    "def predict_sentiment_with_percentages(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits     # Get logits from model output\n",
    "    probs = F.softmax(logits, dim=-1).flatten()     # Convert logits to probabilities using softmax\n",
    "    sentiment_labels = ['negative', 'neutral', 'positive']     # Map the probabilities to their respective sentiment labels\n",
    "    sentiment_percentages = {label: round(prob.item() * 100, 2) for label, prob in zip(sentiment_labels, probs)}\n",
    "    return sentiment_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 23.18, 'neutral': 22.91, 'positive': 53.91}\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "text = \"Should i buy a tesla as Emmanuel said it is good but it also very costly\"\n",
    "result = predict_sentiment_with_percentages(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process Starts Here...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results():\n",
    "    df = pd.read_csv('red_data_4.csv')\n",
    "\n",
    "    sentiment_results = []\n",
    "\n",
    "    # Iterate over the texts in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['comment']\n",
    "        sentiment_percentages = predict_sentiment_with_percentages(text)\n",
    "        sentiment_results.append({\n",
    "            'comment': text,\n",
    "            'negative': sentiment_percentages['negative'],\n",
    "            'neutral': sentiment_percentages['neutral'],\n",
    "            'positive': sentiment_percentages['positive']\n",
    "        })\n",
    "\n",
    "    sentiment_df = pd.DataFrame(sentiment_results)\n",
    "    return sentiment_df['positive'].mean(), sentiment_df['neutral'].mean(), sentiment_df['negative'].mean()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robots with guns does not give me a warm and f...</td>\n",
       "      <td>42.29</td>\n",
       "      <td>15.06</td>\n",
       "      <td>42.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Yee haw\" killed me💀💀</td>\n",
       "      <td>16.53</td>\n",
       "      <td>49.97</td>\n",
       "      <td>33.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dude : \"Now give me back my gun\"\\nRobot : \"giv...</td>\n",
       "      <td>27.58</td>\n",
       "      <td>27.65</td>\n",
       "      <td>44.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guy: Nice job! I’ll take my gun back.\\nRobot: ...</td>\n",
       "      <td>40.93</td>\n",
       "      <td>10.46</td>\n",
       "      <td>48.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*10 seconds later*\\nRobot:\"Now we have to chex...</td>\n",
       "      <td>36.79</td>\n",
       "      <td>22.58</td>\n",
       "      <td>40.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>“Hey Jerry, you got that jack rabbit chip?”\\nJ...</td>\n",
       "      <td>21.54</td>\n",
       "      <td>26.09</td>\n",
       "      <td>52.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>When you see a Terminator and it asks for your...</td>\n",
       "      <td>32.86</td>\n",
       "      <td>12.27</td>\n",
       "      <td>54.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>That shirt gone be wrinkled as hell 😂</td>\n",
       "      <td>33.81</td>\n",
       "      <td>21.01</td>\n",
       "      <td>45.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Such smooth movements. No arthritis</td>\n",
       "      <td>31.91</td>\n",
       "      <td>33.74</td>\n",
       "      <td>34.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This is gonna be the start of the robots right...</td>\n",
       "      <td>24.97</td>\n",
       "      <td>31.24</td>\n",
       "      <td>43.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  negative  neutral  \\\n",
       "0    Robots with guns does not give me a warm and f...     42.29    15.06   \n",
       "1                                \"Yee haw\" killed me💀💀     16.53    49.97   \n",
       "2    Dude : \"Now give me back my gun\"\\nRobot : \"giv...     27.58    27.65   \n",
       "3    Guy: Nice job! I’ll take my gun back.\\nRobot: ...     40.93    10.46   \n",
       "4    *10 seconds later*\\nRobot:\"Now we have to chex...     36.79    22.58   \n",
       "..                                                 ...       ...      ...   \n",
       "995  “Hey Jerry, you got that jack rabbit chip?”\\nJ...     21.54    26.09   \n",
       "996  When you see a Terminator and it asks for your...     32.86    12.27   \n",
       "997              That shirt gone be wrinkled as hell 😂     33.81    21.01   \n",
       "998                Such smooth movements. No arthritis     31.91    33.74   \n",
       "999  This is gonna be the start of the robots right...     24.97    31.24   \n",
       "\n",
       "     positive  \n",
       "0       42.64  \n",
       "1       33.49  \n",
       "2       44.77  \n",
       "3       48.61  \n",
       "4       40.63  \n",
       "..        ...  \n",
       "995     52.38  \n",
       "996     54.86  \n",
       "997     45.19  \n",
       "998     34.35  \n",
       "999     43.79  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  43.271089999999994\n",
      "Neutral:  27.8117\n",
      "Negative:  28.917300000000004\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive: \",sentiment_df['positive'].mean())\n",
    "print(\"Neutral: \",sentiment_df['neutral'].mean())\n",
    "print(\"Negative: \",sentiment_df['negative'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT GEN Model begins here...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Nov/2024 17:00:55] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for Video ID: pBHwJkrz3x4\n",
      "Fetching comments for Video ID: 6R6F371Hj3k\n",
      "Comments are disabled for Video ID: 6R6F371Hj3k. Skipping this video.\n",
      "Fetching comments for Video ID: r1Rrt8iaOUc\n",
      "Fetching comments for Video ID: 43nSDUdse60\n",
      "Fetching comments for Video ID: BDx_YTf9x1g\n",
      "Fetching comments for Video ID: l2q_-xN2N54\n",
      "Fetching comments for Video ID: JC9VVO0aUQw\n",
      "Fetching comments for Video ID: EL1lwZP-RqM\n",
      "Fetching comments for Video ID: 9vwHuCC6nP8\n",
      "Fetching comments for Video ID: _H93VOlHIXo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Nov/2024 17:01:44] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for tesla: None\n",
      "Sentiment scores: (31.837277777777782, 31.000544444444444, 37.16213333333333)\n",
      "Fetching comments for Video ID: cjuMrdQDxYM\n",
      "Fetching comments for Video ID: q4dpodc953M\n",
      "Fetching comments for Video ID: RvhIsm7mr70\n",
      "Fetching comments for Video ID: ihojDlh1UEI\n",
      "Fetching comments for Video ID: ivnOssQGpjY\n",
      "Fetching comments for Video ID: mvnMIyj_KHk\n",
      "Fetching comments for Video ID: lSqjXkVl4s4\n",
      "Fetching comments for Video ID: 5hwY9dFFigU\n",
      "Fetching comments for Video ID: N_o-rwIV7pg\n",
      "Fetching comments for Video ID: dwR6mQCM6vo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Nov/2024 17:03:28] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for bmw: None\n",
      "Sentiment scores: (27.70261, 42.68369, 29.61384)\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def home():\n",
    "    user_input = None\n",
    "    sentiment = None\n",
    "    if request.method == 'POST':\n",
    "        # Get the data from the input box\n",
    "        user_input = request.form['user_input']\n",
    "        search_results = get_search_results_yt(user_input)\n",
    "        p, neu, neg = generate_results()\n",
    "        sentiment = (p, neu, neg)\n",
    "        \n",
    "        # Debugging print statements (optional)\n",
    "        print(f\"Search results for {user_input}: {search_results}\")\n",
    "        print(f\"Sentiment scores: {sentiment}\")\n",
    "        \n",
    "    return render_template_string(\"\"\"\n",
    "        <form method=\"POST\">\n",
    "            <input type=\"text\" name=\"user_input\" placeholder=\"Enter something\">\n",
    "            <input type=\"submit\" value=\"Submit\">\n",
    "        </form>\n",
    "        {% if user_input %}\n",
    "            <h3>Searching: {{ user_input }}</h3>\n",
    "            <p>Results: {{ sentiment }}</p>\n",
    "        {% endif %}\n",
    "    \"\"\", user_input=user_input, sentiment=sentiment)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This will keep the Flask app running until you manually stop it (using Ctrl+C)\n",
    "    app.run(debug=True, use_reloader=False, port = 5001)  # use_reloader=False is important in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
