{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n",
      "Requirement already satisfied: praw in c:\\users\\lab\\anaconda3\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\lab\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.153.0)\n",
      "Requirement already satisfied: flask in c:\\users\\lab\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\lab\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lab\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: transformers==4.46.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: torch==2.3.1+cu121 in c:\\users\\lab\\anaconda3\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision==0.18.1+cu121 in c:\\users\\lab\\anaconda3\\lib\\site-packages (0.18.1+cu121)\n",
      "Requirement already satisfied: accelerate in c:\\users\\lab\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from transformers==4.46.2) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torch==2.3.1+cu121) (2021.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from torchvision==0.18.1+cu121) (10.3.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.36.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.23.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lab\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\lab\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lab\\anaconda3\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.1+cu121) (2.1.3)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\lab\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1+cu121) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\lab\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1+cu121) (2021.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from requests->transformers==4.46.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from requests->transformers==4.46.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from requests->transformers==4.46.2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from requests->transformers==4.46.2) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.1+cu121) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\lab\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\lab\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\lab\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lab\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orchvision (c:\\Users\\Lab\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orchvision (c:\\Users\\Lab\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orchvision (c:\\Users\\Lab\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#installing libs\n",
    "%pip install praw pandas vaderSentiment google-api-python-client flask datasets scikit-learn tensorflow tf-keras transformers==4.46.2 torch==2.3.1+cu121 torchvision==0.18.1+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libs\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "from werkzeug.serving import run_simple\n",
    "import threading\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EvalPrediction, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from flask import Flask, render_template_string, request, session\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping Reddit for Dataset to Train on Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit creds\n",
    "reddit = praw.Reddit(\n",
    "    user_agent=\"Comment Extraction (by /u/lestergreeks)\",\n",
    "    client_id=\"YiK4KHJXxneFv0IiV8aOhg\", \n",
    "    client_secret=\"8GfGLUx8E62B3sBUwJcie43RDBQm7A\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting all comments from top10 posts of a subreddit\n",
    "subreddit = reddit.subreddit('technews')\n",
    "\n",
    "all_comments = pd.DataFrame()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(submission):\n",
    "    posts = []\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    count = 0\n",
    "    for top_level_comment in submission.comments.list():\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        if (top_level_comment.author and \"bot\" not in top_level_comment.author.name.lower() \n",
    "            and not top_level_comment.stickied):\n",
    "            posts.append(top_level_comment.body.encode('utf-8', 'ignore').decode('utf-8'))\n",
    "    \n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_posts():\n",
    "    global all_comments\n",
    "    attempt = 0\n",
    "    for submission in subreddit.rising(limit=15):\n",
    "        try:\n",
    "            print(f\"Processing post: {submission.title}\")\n",
    "            posts = extract_comments(submission)\n",
    "            posts_df = pd.DataFrame(posts, columns=[\"body\"])\n",
    "            indexNames = posts_df[(posts_df.body == '[removed]') | (posts_df.body == '[deleted]')].index\n",
    "            posts_df.drop(indexNames, inplace=True)\n",
    "            posts_df['post_title'] = submission.title\n",
    "            posts_df['post_time'] = datetime.fromtimestamp(submission.created_utc, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            all_comments = pd.concat([all_comments, posts_df], ignore_index=True)\n",
    "        \n",
    "        except praw.exceptions.RedditAPIException as e:\n",
    "            if \"RATELIMIT\" in str(e):\n",
    "                attempt += 1\n",
    "                sleep_time = 120 * attempt\n",
    "                print(f\"Rate limit hit. Sleeping for {sleep_time} seconds. Error: {e}\")\n",
    "                time.sleep(sleep_time) \n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Encountered an error: {e}\")\n",
    "                continue\n",
    "    \n",
    "        time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing post: The ugly truth behind ChatGPT: AI is guzzling resources at planet-eating rates\n",
      "Processing post: Nearly half of young Norwegians are fine with piracy to save money, survey shows | High costs cited as the main reason for piracy acceptance\n",
      "Processing post: Meta Finally Breaks Its Silence on Pig Butchering\n",
      "Processing post: Nearly half of Gen AI adopters want it open source - here's why\n",
      "Processing post: DoJ wants Google to sell Chrome and ban it from paying to be search default | Filing also suggests it sells Android, stops scraping content for AI without opt-out\n",
      "Processing post: Anthropic CEO Says Mandatory Safety Tests Needed for AI Models\n",
      "Processing post: AI can now create a replica of your personality | A two-hour interview is enough to accurately capture your values and preferences, according to new research from Stanford and Google DeepMind.\n",
      "Processing post: Microsoft pushes full-screen ads for Copilot+ PCs on Windows 10 users | Microsoft has frequently used this kind of reminder to encourage upgrades.\n",
      "Processing post: Danish Navy boards Chinese ship suspected in European undersea cable sabotage ‚Äî Sweden‚Äôs Defense Ministry put freighter at the time and place of the disruption | Internet cables connecting Finland to Germany and Lithuania and Sweden were cut\n",
      "Processing post: Relevant! Relevant! Relevant! At 50, Microsoft Is an AI Giant, Open-Source Lover, and as Bad as Ever\n",
      "Processing post: Leak: Valve is making a Steam Controller 2 and a ‚ÄòRoy‚Äô for its Deckard\n",
      "Processing post: D-Link won't patch its older VPN routers, leaving critical vulnerability unaddressed | Instead, it is offering a 20% discount on a newer model\n",
      "Processing post: Inside the Booming ‚ÄòAI Pimping‚Äô Industry | AI-generated influencers based on stolen images of real-life adult content creators are flooding social media.\n",
      "Processing post: An anti-deepfake declaration may have been written by AI\n",
      "Processing post: U.S. Gathers Global Group to Tackle AI Safety Amid Growing National Security Concerns\n"
     ]
    }
   ],
   "source": [
    "process_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seems like an act of war to me if there was sa...</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Suspect' sabotage? Ummm. Should read, *EU lea...</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Didn‚Äôt Russia just threaten this?</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Listen all y‚Äôall this is sabotage.</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It'll be ten by next week\\n\\nFucking grow a sp...</td>\n",
       "      <td>Two undersea internet cables connecting Finlan...</td>\n",
       "      <td>2024-11-19 17:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Money isn‚Äôt a true part of the system. It‚Äôs a ...</td>\n",
       "      <td>Ukraine rolls out dozens of AI systems to help...</td>\n",
       "      <td>2024-11-18 12:04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Maybe attach some electrodes to its GPUs and a...</td>\n",
       "      <td>OpenAI accused of trying to profit off AI mode...</td>\n",
       "      <td>2024-11-19 01:35:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Report; What are your Prime Directives?\\n\\nTha...</td>\n",
       "      <td>OpenAI accused of trying to profit off AI mode...</td>\n",
       "      <td>2024-11-19 01:35:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Attach electrodes to the Sam Altman model and ...</td>\n",
       "      <td>OpenAI accused of trying to profit off AI mode...</td>\n",
       "      <td>2024-11-19 01:35:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Who knows, it might like that</td>\n",
       "      <td>OpenAI accused of trying to profit off AI mode...</td>\n",
       "      <td>2024-11-19 01:35:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    Seems like an act of war to me if there was sa...   \n",
       "1    'Suspect' sabotage? Ummm. Should read, *EU lea...   \n",
       "2                    Didn‚Äôt Russia just threaten this?   \n",
       "3                   Listen all y‚Äôall this is sabotage.   \n",
       "4    It'll be ten by next week\\n\\nFucking grow a sp...   \n",
       "..                                                 ...   \n",
       "473  Money isn‚Äôt a true part of the system. It‚Äôs a ...   \n",
       "474  Maybe attach some electrodes to its GPUs and a...   \n",
       "475  Report; What are your Prime Directives?\\n\\nTha...   \n",
       "476  Attach electrodes to the Sam Altman model and ...   \n",
       "477                      Who knows, it might like that   \n",
       "\n",
       "                                            post_title            post_time  \n",
       "0    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "1    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "2    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "3    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "4    Two undersea internet cables connecting Finlan...  2024-11-19 17:42:55  \n",
       "..                                                 ...                  ...  \n",
       "473  Ukraine rolls out dozens of AI systems to help...  2024-11-18 12:04:35  \n",
       "474  OpenAI accused of trying to profit off AI mode...  2024-11-19 01:35:12  \n",
       "475  OpenAI accused of trying to profit off AI mode...  2024-11-19 01:35:12  \n",
       "476  OpenAI accused of trying to profit off AI mode...  2024-11-19 01:35:12  \n",
       "477  OpenAI accused of trying to profit off AI mode...  2024-11-19 01:35:12  \n",
       "\n",
       "[478 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments.to_csv('red_data_2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labelling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'red_data_2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows to understand the structure\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lol there is an add on this post for pax8 AI ‚Äú...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So AI is killing us, just not the way we expected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTC is right there too</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The same story with every major electricity-us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People who use AI don‚Äôt care</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  score\n",
       "0  lol there is an add on this post for pax8 AI ‚Äú...      2\n",
       "1  So AI is killing us, just not the way we expected      0\n",
       "2                             BTC is right there too      1\n",
       "3  The same story with every major electricity-us...      1\n",
       "4                       People who use AI don‚Äôt care      2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to classify sentiment using VADER\n",
    "def classify_sentiment_vader(text):\n",
    "    sentiment_score = analyzer.polarity_scores(str(text))\n",
    "    # Classify as negative, neutral, or positive based on compound score\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 2  # Positive\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 0  # Negative\n",
    "    else:\n",
    "        return 1  # Neutral\n",
    "\n",
    "# Apply the VADER sentiment classification to the 'body' column\n",
    "data['score'] = data['body'].apply(classify_sentiment_vader)\n",
    "\n",
    "# Check the results\n",
    "data[['body', 'score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('red_data_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Sentimental Analysis on YT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key here\n",
    "API_KEY = \"AIzaSyCKz6fxf2IvH8z8LIp5mpm76LB9u9fxHUU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube Comments Extraction using YT.v3 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get comments for a given video ID\n",
    "def get_comments(video_id, max_comments=100, order=\"relevance\"):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "    \n",
    "    comments = []\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        maxResults=max_comments,\n",
    "        textFormat=\"plainText\",\n",
    "        order=order\n",
    "    )\n",
    "    \n",
    "    while request and len(comments) < max_comments:\n",
    "        try:\n",
    "            response = request.execute()\n",
    "        \n",
    "            # Loop through each comment in the response\n",
    "            for item in response.get(\"items\", []):\n",
    "                full_comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append(full_comment)  # Store the full comment\n",
    "                \n",
    "                # Stop if we have reached the max comments\n",
    "                if len(comments) >= max_comments:\n",
    "                    break\n",
    "        \n",
    "            # Check for more comments (pagination)\n",
    "            request = youtube.commentThreads().list_next(request, response)\n",
    "        except HttpError as e:\n",
    "            if \"commentsDisabled\" in str(e):\n",
    "                print(f\"Comments are disabled for Video ID: {video_id}. Skipping this video.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"An unexpected error occurred with Video ID: {video_id}. Error: {e}\")\n",
    "                break\n",
    "\n",
    "    return comments[:max_comments]  # Return up to max_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_videos(query, max_videos=10):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "    \n",
    "    # Search for videos based on the query\n",
    "    request = youtube.search().list(\n",
    "        q=query,\n",
    "        part=\"snippet\",\n",
    "        order=\"viewCount\",\n",
    "        maxResults=max_videos,\n",
    "        type=\"video\"\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    video_data = []  # List to hold video data and comments\n",
    "\n",
    "    for item in response.get(\"items\", []):\n",
    "        video_id = item[\"id\"][\"videoId\"]\n",
    "        video_title = item[\"snippet\"][\"title\"]  # Get video title\n",
    "        print(f\"Fetching comments for Video ID: {video_id}\") \n",
    "        \n",
    "        # Get comments and handle errors (skipping videos with disabled comments)\n",
    "        comments = get_comments(video_id)\n",
    "        \n",
    "        if comments:  # If comments were successfully fetched\n",
    "            for comment in comments:\n",
    "                video_data.append({\"video_id\": video_id, \"video_title\": video_title, \"comment\": comment})\n",
    "    \n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER INPUT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for Video ID: 2cukB4_hDCI\n",
      "Fetching comments for Video ID: DxREm3s1scA\n",
      "Fetching comments for Video ID: cpraXaw7dyc\n",
      "Fetching comments for Video ID: 2lLZ9AWhcNo\n",
      "Fetching comments for Video ID: XiQkeWOFwmk\n",
      "Fetching comments for Video ID: fgm5uZaS3-E\n",
      "Fetching comments for Video ID: DB1027Bfpmo\n",
      "Fetching comments for Video ID: Mu-eK72ioDk\n",
      "Fetching comments for Video ID: nAgTgwak7ME\n",
      "Fetching comments for Video ID: 8vsTNFUFJEU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Robots with guns does not give me a warm and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>\"Yee haw\" killed meüíÄüíÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Dude : \"Now give me back my gun\"\\nRobot : \"giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Guy: Nice job! I‚Äôll take my gun back.\\nRobot: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>*10 seconds later*\\nRobot:\"Now we have to chex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                 video_title  \\\n",
       "0  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "1  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "2  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "3  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "4  2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "\n",
       "                                             comment  \n",
       "0  Robots with guns does not give me a warm and f...  \n",
       "1                              \"Yee haw\" killed meüíÄüíÄ  \n",
       "2  Dude : \"Now give me back my gun\"\\nRobot : \"giv...  \n",
       "3  Guy: Nice job! I‚Äôll take my gun back.\\nRobot: ...  \n",
       "4  *10 seconds later*\\nRobot:\"Now we have to chex...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"tesla we robot\"  # Your search query\n",
    "top_videos_comments = get_top_videos(query, max_videos=10)  # Fetch top 10 videos\n",
    "\n",
    "# Convert the results into a DataFrame for better readability\n",
    "df = pd.DataFrame(top_videos_comments)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Robots with guns does not give me a warm and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>\"Yee haw\" killed meüíÄüíÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Dude : \"Now give me back my gun\"\\nRobot : \"giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>Guy: Nice job! I‚Äôll take my gun back.\\nRobot: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2cukB4_hDCI</td>\n",
       "      <td>Robots testing the Bulletproof #cybertruck</td>\n",
       "      <td>*10 seconds later*\\nRobot:\"Now we have to chex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>‚ÄúHey Jerry, you got that jack rabbit chip?‚Äù\\nJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>When you see a Terminator and it asks for your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>That shirt gone be wrinkled as hell üòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>Such smooth movements. No arthritis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>8vsTNFUFJEU</td>\n",
       "      <td>Tesla Optimus Bot FOLDS the Laundry !</td>\n",
       "      <td>This is gonna be the start of the robots right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                 video_title  \\\n",
       "0    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "1    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "2    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "3    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "4    2cukB4_hDCI  Robots testing the Bulletproof #cybertruck   \n",
       "..           ...                                         ...   \n",
       "995  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "996  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "997  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "998  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "999  8vsTNFUFJEU       Tesla Optimus Bot FOLDS the Laundry !   \n",
       "\n",
       "                                               comment  \n",
       "0    Robots with guns does not give me a warm and f...  \n",
       "1                                \"Yee haw\" killed meüíÄüíÄ  \n",
       "2    Dude : \"Now give me back my gun\"\\nRobot : \"giv...  \n",
       "3    Guy: Nice job! I‚Äôll take my gun back.\\nRobot: ...  \n",
       "4    *10 seconds later*\\nRobot:\"Now we have to chex...  \n",
       "..                                                 ...  \n",
       "995  ‚ÄúHey Jerry, you got that jack rabbit chip?‚Äù\\nJ...  \n",
       "996  When you see a Terminator and it asks for your...  \n",
       "997              That shirt gone be wrinkled as hell üòÇ  \n",
       "998                Such smooth movements. No arthritis  \n",
       "999  This is gonna be the start of the robots right...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('red_data_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results_yt(query):\n",
    "    top_videos_comments = get_top_videos(query, max_videos=10)  # Fetch top 10 videos\n",
    "\n",
    "    # Convert the results into a DataFrame for better readability\n",
    "    df = pd.DataFrame(top_videos_comments)\n",
    "    df.to_csv('red_data_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Model begins here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model v3.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('red_data_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to Dataset format compatible with Hugging Face Trainer\n",
    "def preprocess_data(df):\n",
    "    return {'text': df['body'], 'label': df['score']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(df))\n",
    "train_data = df[:train_size]\n",
    "test_data = df[train_size:]\n",
    "\n",
    "# Apply preprocessing and convert the data into the proper format\n",
    "preprocessed_train = df[:train_size].apply(preprocess_data, axis=1).to_list()\n",
    "preprocessed_test = df[train_size:].apply(preprocess_data, axis=1).to_list()\n",
    "# Convert preprocessed data into Dataset objects\n",
    "train_dataset = Dataset.from_list(preprocessed_train)\n",
    "test_dataset = Dataset.from_list(preprocessed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cb681c4be24c9f920524ef22a97169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b2da791ecf451a981570c319203c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "# Set format to PyTorch tensors for Trainer\n",
    "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lab\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',               # output directory\n",
    "    evaluation_strategy=\"epoch\",          # evaluation strategy (evaluate at the end of each epoch)\n",
    "    learning_rate=2e-5,                   # learning rate\n",
    "    per_device_train_batch_size=16,       # batch size for training\n",
    "    per_device_eval_batch_size=16,        # batch size for evaluation\n",
    "    num_train_epochs=3,                   # number of training epochs\n",
    "    weight_decay=0.01,                    # strength of weight decay\n",
    "    logging_dir='./logs',                 # directory for storing logs\n",
    "    logging_steps=10,                     # log every 10 steps\n",
    "    save_strategy=\"epoch\"                 # save model at the end of every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred: EvalPrediction):\n",
    "    predictions, labels = pred.predictions, pred.label_ids\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_score': f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bec62dfde9f4accbcfe311f66ebf58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lab\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0723, 'grad_norm': 6.605048656463623, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.38}\n",
      "{'loss': 1.0083, 'grad_norm': 9.588112831115723, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb5d9bb01134dd98e17e64266fdea08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0402607917785645, 'eval_accuracy': 0.4326923076923077, 'eval_f1_score': 0.3539048097871627, 'eval_runtime': 0.8942, 'eval_samples_per_second': 116.304, 'eval_steps_per_second': 7.828, 'epoch': 1.0}\n",
      "{'loss': 1.0388, 'grad_norm': 8.461682319641113, 'learning_rate': 1.230769230769231e-05, 'epoch': 1.15}\n",
      "{'loss': 0.9454, 'grad_norm': 7.225735664367676, 'learning_rate': 9.743589743589744e-06, 'epoch': 1.54}\n",
      "{'loss': 0.9027, 'grad_norm': 5.839921951293945, 'learning_rate': 7.17948717948718e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edac71bac1ff46e18f94f3b49756a6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0357333421707153, 'eval_accuracy': 0.47115384615384615, 'eval_f1_score': 0.4515640369860319, 'eval_runtime': 0.9008, 'eval_samples_per_second': 115.449, 'eval_steps_per_second': 7.771, 'epoch': 2.0}\n",
      "{'loss': 0.8961, 'grad_norm': 7.317960739135742, 'learning_rate': 4.615384615384616e-06, 'epoch': 2.31}\n",
      "{'loss': 0.8459, 'grad_norm': 7.210404396057129, 'learning_rate': 2.0512820512820513e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ca88df9418473cbdd02c8f4b634f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0575743913650513, 'eval_accuracy': 0.49038461538461536, 'eval_f1_score': 0.4852919344234481, 'eval_runtime': 1.0323, 'eval_samples_per_second': 100.742, 'eval_steps_per_second': 6.781, 'epoch': 3.0}\n",
      "{'train_runtime': 59.2183, 'train_samples_per_second': 20.872, 'train_steps_per_second': 1.317, 'train_loss': 0.9570341354761368, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=78, training_loss=0.9570341354761368, metrics={'train_runtime': 59.2183, 'train_samples_per_second': 20.872, 'train_steps_per_second': 1.317, 'total_flos': 325208184311808.0, 'train_loss': 0.9570341354761368, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bert_tokenizer\\\\tokenizer_config.json',\n",
       " './fine_tuned_bert_tokenizer\\\\special_tokens_map.json',\n",
       " './fine_tuned_bert_tokenizer\\\\vocab.txt',\n",
       " './fine_tuned_bert_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine_tuned_bert_model')\n",
    "tokenizer.save_pretrained('./fine_tuned_bert_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('./fine_tuned_bert_model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./fine_tuned_bert_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to predict sentiment with percentage outputs\n",
    "def predict_sentiment_with_percentages(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits     # Get logits from model output\n",
    "    probs = F.softmax(logits, dim=-1).flatten()     # Convert logits to probabilities using softmax\n",
    "    sentiment_labels = ['negative', 'neutral', 'positive']     # Map the probabilities to their respective sentiment labels\n",
    "    sentiment_percentages = {label: round(prob.item() * 100, 2) for label, prob in zip(sentiment_labels, probs)}\n",
    "    return sentiment_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 23.18, 'neutral': 22.91, 'positive': 53.91}\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "text = \"Should i buy a tesla as Emmanuel said it is good but it also very costly\"\n",
    "result = predict_sentiment_with_percentages(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process Starts Here...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results():\n",
    "    df = pd.read_csv('red_data_4.csv')\n",
    "\n",
    "    sentiment_results = []\n",
    "\n",
    "    # Iterate over the texts in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['comment']\n",
    "        sentiment_percentages = predict_sentiment_with_percentages(text)\n",
    "        sentiment_results.append({\n",
    "            'comment': text,\n",
    "            'negative': sentiment_percentages['negative'],\n",
    "            'neutral': sentiment_percentages['neutral'],\n",
    "            'positive': sentiment_percentages['positive']\n",
    "        })\n",
    "\n",
    "    sentiment_df = pd.DataFrame(sentiment_results)\n",
    "    return sentiment_df['positive'].mean().__round__(2), sentiment_df['neutral'].mean().__round__(2), sentiment_df['negative'].mean().__round__(2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robots with guns does not give me a warm and f...</td>\n",
       "      <td>42.29</td>\n",
       "      <td>15.06</td>\n",
       "      <td>42.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Yee haw\" killed meüíÄüíÄ</td>\n",
       "      <td>16.53</td>\n",
       "      <td>49.97</td>\n",
       "      <td>33.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dude : \"Now give me back my gun\"\\nRobot : \"giv...</td>\n",
       "      <td>27.58</td>\n",
       "      <td>27.65</td>\n",
       "      <td>44.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guy: Nice job! I‚Äôll take my gun back.\\nRobot: ...</td>\n",
       "      <td>40.93</td>\n",
       "      <td>10.46</td>\n",
       "      <td>48.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*10 seconds later*\\nRobot:\"Now we have to chex...</td>\n",
       "      <td>36.79</td>\n",
       "      <td>22.58</td>\n",
       "      <td>40.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>‚ÄúHey Jerry, you got that jack rabbit chip?‚Äù\\nJ...</td>\n",
       "      <td>21.54</td>\n",
       "      <td>26.09</td>\n",
       "      <td>52.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>When you see a Terminator and it asks for your...</td>\n",
       "      <td>32.86</td>\n",
       "      <td>12.27</td>\n",
       "      <td>54.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>That shirt gone be wrinkled as hell üòÇ</td>\n",
       "      <td>33.81</td>\n",
       "      <td>21.01</td>\n",
       "      <td>45.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Such smooth movements. No arthritis</td>\n",
       "      <td>31.91</td>\n",
       "      <td>33.74</td>\n",
       "      <td>34.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This is gonna be the start of the robots right...</td>\n",
       "      <td>24.97</td>\n",
       "      <td>31.24</td>\n",
       "      <td>43.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  negative  neutral  \\\n",
       "0    Robots with guns does not give me a warm and f...     42.29    15.06   \n",
       "1                                \"Yee haw\" killed meüíÄüíÄ     16.53    49.97   \n",
       "2    Dude : \"Now give me back my gun\"\\nRobot : \"giv...     27.58    27.65   \n",
       "3    Guy: Nice job! I‚Äôll take my gun back.\\nRobot: ...     40.93    10.46   \n",
       "4    *10 seconds later*\\nRobot:\"Now we have to chex...     36.79    22.58   \n",
       "..                                                 ...       ...      ...   \n",
       "995  ‚ÄúHey Jerry, you got that jack rabbit chip?‚Äù\\nJ...     21.54    26.09   \n",
       "996  When you see a Terminator and it asks for your...     32.86    12.27   \n",
       "997              That shirt gone be wrinkled as hell üòÇ     33.81    21.01   \n",
       "998                Such smooth movements. No arthritis     31.91    33.74   \n",
       "999  This is gonna be the start of the robots right...     24.97    31.24   \n",
       "\n",
       "     positive  \n",
       "0       42.64  \n",
       "1       33.49  \n",
       "2       44.77  \n",
       "3       48.61  \n",
       "4       40.63  \n",
       "..        ...  \n",
       "995     52.38  \n",
       "996     54.86  \n",
       "997     45.19  \n",
       "998     34.35  \n",
       "999     43.79  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  43.271089999999994\n",
      "Neutral:  27.8117\n",
      "Negative:  28.917300000000004\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive: \",sentiment_df['positive'].mean())\n",
    "print(\"Neutral: \",sentiment_df['neutral'].mean())\n",
    "print(\"Negative: \",sentiment_df['negative'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 4 (DO NOT RUN THIS!) - MODEL NOT STABLE‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT GEN Model begins here...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "# Assign a padding token if not already present\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as the pad_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input text and set up labels\n",
    "def tokenize_function(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].copy()  # Set the labels as input_ids\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert dataset to PyTorch tensors\n",
    "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = tokenized_datasets[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tokenizer.pad(batch, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=1,  # Disable multiprocessing to debug\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "scaler = GradScaler()  # Initialize the scaler for mixed precision\n",
    "\n",
    "# Set gradient accumulation steps (adjust to simulate larger batches)\n",
    "accumulation_steps = 4  # Simulates larger batch size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(train_dataloader, leave=True)\n",
    "\n",
    "    optimizer.zero_grad()  # Reset the gradients before starting\n",
    "\n",
    "    for step, batch in enumerate(loop):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "\n",
    "        with torch.cuda.amp.autocast():  # Enable mixed precision\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss / accumulation_steps  # Scale loss for accumulation\n",
    "\n",
    "        scaler.scale(loss).backward()  # Backpropagate loss\n",
    "\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)  # Update weights\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lab\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lab\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? Tell me about Tesla Motors!\n",
      "I'm a big fan of the company and I've been working on it for years. It's one of my favorite cars ever made, but there is something special that makes this car so unique to us: The way we build our vehicles in such an innovative manner allows them not only to be built with high quality materials (like aluminum), they can also have their own custom parts available from suppliers like BMW or Mercedes-Benz as well ‚Äì all without having to worry too much over what will happen when these components go into production‚Ä¶and then get shipped out by truck every year.\"\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set pad token to eos token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Move model to the correct device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Prepare input text and move to device\n",
    "input_text = \"How are you? Tell me about Tesla Motors!\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Create attention mask to differentiate between padding and actual data\n",
    "attention_mask = torch.ones(inputs.shape, device=device)\n",
    "\n",
    "# Generate text with repetition penalty\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=150,  # Increased length to avoid truncation\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        temperature=0.8,  # Slightly adjusted temperature\n",
    "        top_k=50,         # Limit next token choices to top-k\n",
    "        top_p=0.9,        # Use nucleus sampling\n",
    "        repetition_penalty=1.2  # Penalty to discourage repetition\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyDYCwFViLa0Ry51BxOdLYZSU4JdkMF3kSY\")\n",
    "\n",
    "model2 = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tex(user_input):\n",
    "\n",
    "    response = model2.generate_content(f\"write a mail to {user_input} for partnership with my company in the future\")\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [22/Nov/2024 12:00:54] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for Video ID: cjuMrdQDxYM\n",
      "Fetching comments for Video ID: q4dpodc953M\n",
      "Fetching comments for Video ID: RvhIsm7mr70\n",
      "Fetching comments for Video ID: ihojDlh1UEI\n",
      "Fetching comments for Video ID: ivnOssQGpjY\n",
      "Fetching comments for Video ID: mvnMIyj_KHk\n",
      "Fetching comments for Video ID: oeCdxQP6UCw\n",
      "Fetching comments for Video ID: lSqjXkVl4s4\n",
      "Fetching comments for Video ID: 5hwY9dFFigU\n",
      "Fetching comments for Video ID: N_o-rwIV7pg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2024 12:01:36] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: bmw\n",
      "Sentiment scores: Positive: 31.56, Neutral: 45.34, Negative: 23.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2024 12:01:42] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: bmw\n",
      "Sentiment scores: Positive: 31.56, Neutral: 45.34, Negative: 23.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2024 12:01:49] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: bmw\n",
      "Sentiment scores: Positive: 31.56, Neutral: 45.34, Negative: 23.09\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "app.secret_key = \"mypopeshighonweed\"\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def home():\n",
    "    user_input = \"\"\n",
    "    sentiment = session.get('sentiment', None)\n",
    "    generated_text = None\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        # Get the data from the input box\n",
    "        user_input = request.form['user_input'].strip()\n",
    "\n",
    "        if not user_input:  # Validate input\n",
    "            generated_text = \"Please enter a valid input before submitting.\"\n",
    "        elif 'search' in request.form:\n",
    "            search_results = get_search_results_yt(user_input)\n",
    "            p, neu, neg = generate_results()\n",
    "            sentiment = f\"Positive: {p}, Neutral: {neu}, Negative: {neg}\"\n",
    "            session['sentiment'] = sentiment\n",
    "        elif 'generate' in request.form:\n",
    "            generated_text = gen_tex(user_input)\n",
    "        \n",
    "        # Debugging print statements (optional)\n",
    "        print(f\"Search: {user_input}\")\n",
    "        print(f\"Sentiment scores: {sentiment}\")\n",
    "        \n",
    "    return render_template_string(\"\"\"\n",
    "        <form method=\"POST\">\n",
    "            <input type=\"text\" name=\"user_input\" placeholder=\"Enter something\" value=\"{{ user_input }}\">\n",
    "            <button type=\"submit\" name=\"search\">Search</button>\n",
    "            <button type=\"submit\" name=\"generate\">Generate</button>\n",
    "        </form>\n",
    "        {% if user_input %}\n",
    "            <h3>Searching: {{ user_input }}</h3>\n",
    "            <p>Results: {{ sentiment }}</p>\n",
    "        {% endif %}\n",
    "        {% if user_input and generated_text %}\n",
    "            <h3>Generated Text:</h3>\n",
    "            <p>{{ generated_text }}</p>\n",
    "        {% endif %}\n",
    "    \"\"\", user_input=user_input, sentiment=sentiment, generated_text=generated_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This will keep the Flask app running until you manually stop it (using Ctrl+C)\n",
    "    app.run(debug=True, use_reloader=False, port = 5001)  # use_reloader=False is important in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
