{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (7.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lester greeks\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lester greeks\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lester greeks\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (2024.6.2)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#installing libs\n",
    "%pip install praw pandas vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libs for scraping\n",
    "import praw\n",
    "import pandas as pd\n",
    "from praw.models import MoreComments\n",
    "import time\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit creds\n",
    "reddit = praw.Reddit(\n",
    "    user_agent=\"\",\n",
    "    client_id=\"\", \n",
    "    client_secret=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a reddit post\n",
    "#https://www.reddit.com/r/IndiaSpeaks/comments/1fr7tyb/scrap_dealer_gifts_multiple_iphones_to_son_for/ - apple test\n",
    "url = \"https://www.reddit.com/r/IndiaSpeaks/comments/1fqhbsz/youtuber_ranveer_allahbadias_youtube_channel_got/\"\n",
    "submission = reddit.submission(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all comments from a post\n",
    "submission.comments.replace_more(limit=None)\n",
    "posts = []\n",
    "for top_level_comment in submission.comments.list():\n",
    "    if isinstance(top_level_comment, MoreComments):\n",
    "        continue\n",
    "    if top_level_comment.author and \"bot\" not in top_level_comment.author.name.lower() and not top_level_comment.stickied:\n",
    "        posts.append(top_level_comment.body)\n",
    "posts = pd.DataFrame(posts,columns=[\"body\"])\n",
    "indexNames = posts[(posts.body == '[removed]') | (posts.body == '[deleted]')].index\n",
    "posts.drop(indexNames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I heard both his passwords where 1234567@ ðŸ’€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hogya recover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was the hackers who showed him the next doo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What this basically tells is that:\\n\\n\"Life is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the exact reason why India should deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>YouTube has decades worth of data plus backed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Yes they can join. But Youtube algo recommends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1. This is completely unrelated to Ranbir's ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Lmao yoh are placing to much importance on tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>No one was livestreaming on YouTube when twitc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body\n",
       "0         I heard both his passwords where 1234567@ ðŸ’€\n",
       "1                                       Hogya recover\n",
       "2   It was the hackers who showed him the next doo...\n",
       "3   What this basically tells is that:\\n\\n\"Life is...\n",
       "4   This is the exact reason why India should deve...\n",
       "..                                                ...\n",
       "67  YouTube has decades worth of data plus backed ...\n",
       "68  Yes they can join. But Youtube algo recommends...\n",
       "69  1. This is completely unrelated to Ranbir's ch...\n",
       "70  Lmao yoh are placing to much importance on tec...\n",
       "71  No one was livestreaming on YouTube when twitc...\n",
       "\n",
       "[72 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting all comments from top10 posts of a subreddit\n",
    "subreddit = reddit.subreddit('technews')\n",
    "\n",
    "all_comments = pd.DataFrame()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(submission):\n",
    "    posts = []\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    count = 0\n",
    "    for top_level_comment in submission.comments.list():\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        if (top_level_comment.author and \"bot\" not in top_level_comment.author.name.lower() \n",
    "            and not top_level_comment.stickied):\n",
    "            posts.append(top_level_comment.body.encode('utf-8', 'ignore').decode('utf-8'))\n",
    "    \n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_posts():\n",
    "    global all_comments\n",
    "    attempt = 0\n",
    "    for submission in subreddit.rising(limit=15):\n",
    "        try:\n",
    "            print(f\"Processing post: {submission.title}\")\n",
    "            posts = extract_comments(submission)\n",
    "            posts_df = pd.DataFrame(posts, columns=[\"body\"])\n",
    "            indexNames = posts_df[(posts_df.body == '[removed]') | (posts_df.body == '[deleted]')].index\n",
    "            posts_df.drop(indexNames, inplace=True)\n",
    "            posts_df['post_title'] = submission.title\n",
    "            posts_df['post_time'] = datetime.fromtimestamp(submission.created_utc, tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            all_comments = pd.concat([all_comments, posts_df], ignore_index=True)\n",
    "        \n",
    "        except praw.exceptions.RedditAPIException as e:\n",
    "            if \"RATELIMIT\" in str(e):\n",
    "                attempt += 1\n",
    "                sleep_time = 120 * attempt\n",
    "                print(f\"Rate limit hit. Sleeping for {sleep_time} seconds. Error: {e}\")\n",
    "                time.sleep(sleep_time) \n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Encountered an error: {e}\")\n",
    "                continue\n",
    "    \n",
    "        time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing post: The Optimus robots at Teslaâ€™s Cybercab event were humans in disguise\n",
      "Processing post: New Gmail Security Alert For 2.5 Billion Users As AI Hack Confirmed\n",
      "Processing post: Apple made a huge macOS privacy promise four years ago, but it's still unfulfilled\n",
      "Processing post: SpaceX successfully catches returning Starship booster \n",
      "Processing post: This AI can think like an engineerâ€”and it just designed a spaceship engine\n",
      "Processing post: TikTok Lays Off Hundreds of Staffâ€”to Replace Them With AI\n",
      "Processing post: Silicon Valley is debating if AI weapons should be allowed to decide to kill\n",
      "Processing post: Hacked Robot Vacuums Across the U.S. Started Yelling Slurs\n",
      "Processing post: Steam now tells gamers up front that they're buying a license, not a game | The company appears to be getting ahead of a California law going into force next year.\n",
      "Processing post: OpenAI says Chinese gang tried to phish its staff\n",
      "Processing post: Marriott settles with FTC, to pay $52 million over data breaches\n",
      "Processing post: Are Teslaâ€™s robot prototypes AI marvels or remote-controlled toys?\n",
      "Processing post: Google says the YouTube skip ad button isn't gone, it's just different\n",
      "Processing post: Open-source AI definition finally gets its first release candidate - and a compromise\n",
      "Processing post: Hacktivists Claim Responsibility for Taking Down the Internet Archive | A pro-Palestinian group has compromised the login information for the worldâ€™s biggest digital archive and launched a sustained DDoS attack against the site.\n"
     ]
    }
   ],
   "source": [
    "process_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was admittedly a bit uncomfortable when my A...</td>\n",
       "      <td>The Optimus robots at Teslaâ€™s Cybercab event w...</td>\n",
       "      <td>2024-10-13 18:08:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Mechanical Turk, classic.</td>\n",
       "      <td>The Optimus robots at Teslaâ€™s Cybercab event w...</td>\n",
       "      <td>2024-10-13 18:08:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Teleoperated, so not quite Russian robots.</td>\n",
       "      <td>The Optimus robots at Teslaâ€™s Cybercab event w...</td>\n",
       "      <td>2024-10-13 18:08:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I could see a transition phase where teleworke...</td>\n",
       "      <td>The Optimus robots at Teslaâ€™s Cybercab event w...</td>\n",
       "      <td>2024-10-13 18:08:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These robotics arenâ€™t even particularly ground...</td>\n",
       "      <td>The Optimus robots at Teslaâ€™s Cybercab event w...</td>\n",
       "      <td>2024-10-13 18:08:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Ok Ivan</td>\n",
       "      <td>Hacktivists Claim Responsibility for Taking Do...</td>\n",
       "      <td>2024-10-10 15:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>First link states the name of the org. Second ...</td>\n",
       "      <td>Hacktivists Claim Responsibility for Taking Do...</td>\n",
       "      <td>2024-10-10 15:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>Jesus Christ some people just canâ€™t admit when...</td>\n",
       "      <td>Hacktivists Claim Responsibility for Taking Do...</td>\n",
       "      <td>2024-10-10 15:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>You totally missed the point. A misleading tit...</td>\n",
       "      <td>Hacktivists Claim Responsibility for Taking Do...</td>\n",
       "      <td>2024-10-10 15:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>Man discovers that mainstream media lacks ethi...</td>\n",
       "      <td>Hacktivists Claim Responsibility for Taking Do...</td>\n",
       "      <td>2024-10-10 15:02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1197 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  \\\n",
       "0     I was admittedly a bit uncomfortable when my A...   \n",
       "1                         The Mechanical Turk, classic.   \n",
       "2            Teleoperated, so not quite Russian robots.   \n",
       "3     I could see a transition phase where teleworke...   \n",
       "4     These robotics arenâ€™t even particularly ground...   \n",
       "...                                                 ...   \n",
       "1192                                            Ok Ivan   \n",
       "1193  First link states the name of the org. Second ...   \n",
       "1194  Jesus Christ some people just canâ€™t admit when...   \n",
       "1195  You totally missed the point. A misleading tit...   \n",
       "1196  Man discovers that mainstream media lacks ethi...   \n",
       "\n",
       "                                             post_title            post_time  \n",
       "0     The Optimus robots at Teslaâ€™s Cybercab event w...  2024-10-13 18:08:39  \n",
       "1     The Optimus robots at Teslaâ€™s Cybercab event w...  2024-10-13 18:08:39  \n",
       "2     The Optimus robots at Teslaâ€™s Cybercab event w...  2024-10-13 18:08:39  \n",
       "3     The Optimus robots at Teslaâ€™s Cybercab event w...  2024-10-13 18:08:39  \n",
       "4     The Optimus robots at Teslaâ€™s Cybercab event w...  2024-10-13 18:08:39  \n",
       "...                                                 ...                  ...  \n",
       "1192  Hacktivists Claim Responsibility for Taking Do...  2024-10-10 15:02:00  \n",
       "1193  Hacktivists Claim Responsibility for Taking Do...  2024-10-10 15:02:00  \n",
       "1194  Hacktivists Claim Responsibility for Taking Do...  2024-10-10 15:02:00  \n",
       "1195  Hacktivists Claim Responsibility for Taking Do...  2024-10-10 15:02:00  \n",
       "1196  Hacktivists Claim Responsibility for Taking Do...  2024-10-10 15:02:00  \n",
       "\n",
       "[1197 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments.to_csv('red_data_2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labelling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'red_data_2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows to understand the structure\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was admittedly a bit uncomfortable when my A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Mechanical Turk, classic.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Teleoperated, so not quite Russian robots.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I could see a transition phase where teleworke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These robotics arenâ€™t even particularly ground...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  score\n",
       "0  I was admittedly a bit uncomfortable when my A...      0\n",
       "1                      The Mechanical Turk, classic.      1\n",
       "2         Teleoperated, so not quite Russian robots.      1\n",
       "3  I could see a transition phase where teleworke...      1\n",
       "4  These robotics arenâ€™t even particularly ground...      1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to classify sentiment using VADER\n",
    "def classify_sentiment_vader(text):\n",
    "    sentiment_score = analyzer.polarity_scores(str(text))\n",
    "    # Classify as negative, neutral, or positive based on compound score\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 2  # Positive\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 0  # Negative\n",
    "    else:\n",
    "        return 1  # Neutral\n",
    "\n",
    "# Apply the VADER sentiment classification to the 'body' column\n",
    "data['score'] = data['body'].apply(classify_sentiment_vader)\n",
    "\n",
    "# Check the results\n",
    "data[['body', 'score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('red_data_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
